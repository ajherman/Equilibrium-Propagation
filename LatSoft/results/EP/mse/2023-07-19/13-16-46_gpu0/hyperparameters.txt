../main.py --task CIFAR10 --model CNN --channels 128 256 512 --paddings 1 1 1 --strides 1 1 1 --kernels 3 3 3 --pools mmm --fc 10 --optim adam --lrs 5e-5 4e-5 6e-5 3e-5 --epochs 20 --act mysig --todo train --betas 0.0 0.01 --T1 150 --T2 15 --mbs 128 --thirdphase --loss mse --save --device 0 --load-path-convert ../Laborieux-Arch/results/EP/cel/2023-07-18/12-05-15_gpu0_copy_5epochs --convert-place-layers 0 1 2 - - 

- task: CIFAR10
- data augmentation (if CIFAR10): False
- learning rate decay: False
- scale for weight init: None
- activation: mysig
- learning rates: [5e-05, 4e-05, 6e-05, 3e-05]
- weight decays: None
- momentum (if sgd): 0.0
- optimizer: adam
- loss: mse
- alg: EP
- minibatch size: 128
- T1: 150
- T2: 15
- betas: [0.0, 0.01]
- random beta_2 sign: False
- thirdphase: True
- softmax: False
- same update VFCNN: False
- epochs: 20
- seed: None
- device: 0

Poolings : [MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)] 

P_CNN(
  (synapses): ModuleList(
    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): Linear(in_features=8192, out_features=10, bias=True)
  )
)
