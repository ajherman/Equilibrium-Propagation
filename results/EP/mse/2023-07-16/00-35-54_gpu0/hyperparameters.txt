main.py --model RevLatCNN --task MNIST --channels 32 64 --kernels 5 5 --pools aa --strides 1 1 1 --paddings 0 0 0 --fc 10 --optim adam --lrs 4e-5 5e-5 3e-5 --epochs 10 --act mysig --todo train --thirdphase --betas 0.0 0.02 --T1 100 --T2 10 --mbs 128 --loss mse --device 0 --seed 0715 --tensorboard --use-lateral --lat-layers 1 2 3 --lat-lrs 6e-5 4e-5 6e-5 --save 

- task: MNIST
- data augmentation (if CIFAR10): False
- learning rate decay: False
- scale for weight init: None
- activation: mysig
- learning rates: [4e-05, 5e-05, 3e-05]
- weight decays: None
- momentum (if sgd): 0.0
- optimizer: adam
- loss: mse
- alg: EP
- minibatch size: 128
- T1: 100
- T2: 10
- betas: [0.0, 0.02]
- random beta_2 sign: False
- thirdphase: True
- softmax: False
- same update VFCNN: False
- epochs: 10
- seed: 715
- device: 0

Poolings : [AvgPool2d(kernel_size=2, stride=2, padding=0), AvgPool2d(kernel_size=2, stride=2, padding=0)] 

RevLatCNN(
  (synapses): ModuleList(
    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))
    (1): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (2): Linear(in_features=1024, out_features=10, bias=True)
  )
  (lat_syn): ModuleList(
    (0): Linear(in_features=4608, out_features=4608, bias=True)
    (1): Linear(in_features=1024, out_features=1024, bias=True)
    (2): Linear(in_features=10, out_features=10, bias=True)
  )
)
